# -*- coding: utf-8 -*-
"""classification 2 after

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oix-D4OmzqBXLQKuaIvG9HkcXXOx-QMW
"""

"""Test script CS.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KMnJOuTbjwivuI_LdSLKcAJjLKtjL8uh
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import sklearn as sk
from sklearn.linear_model import Ridge , Lasso
from sklearn.ensemble import RandomForestRegressor , GradientBoostingRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from sklearn.preprocessing import RobustScaler
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.pipeline import make_pipeline
from sklearn.tree import DecisionTreeRegressor
from sklearn.feature_selection import mutual_info_classif
from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestRegressor
import pickle

data = pd.read_csv(r"/content/ElecClassTest.csv")

df_train, df_test = train_test_split(data, test_size=0.2, random_state=20)

print(df_test)

print(df_train)

df_test.head()

df_test.shape

with open('preprocessing_steps.pkl', 'rb') as f:
    preprocessing_steps = pickle.load(f)

for column, replacements in preprocessing_steps.items():
    if column in df_test.columns:
        try:
            df_test[column] = df_test[column].replace(replacements)
        except Exception as e:
            print(f"Error occurred while replacing values in column '{column}': {e}")

df_test['processor_gnrtn'].value_counts()

with open('modes.pkl', 'rb') as f:
    modes_loaded = pickle.load(f)

for column in df_test.columns:
    mode_value = modes_loaded.get(column)
    if mode_value is not None:
        df_test[column].fillna(mode_value, inplace=True)

df_test['ram_gb'].value_counts()

df_test['os'].value_counts()

import pandas as pd
import pickle
import re

columns_to_process = ['ram_gb', 'ssd', 'hdd', 'os', 'graphic_card_gb', 'warranty','processor_gnrtn']






number_regex = r'\d+\.?\d*'

for column in columns_to_process:
    if column in df_test.columns:
        original_values = df_test[column].unique()
        split_values = [re.search(number_regex, value).group() if re.search(number_regex, value) else value for value in original_values.astype(str)]



        df_test[column] = df_test[column].astype(str).apply(lambda x: re.search(number_regex, x).group() if re.search(number_regex, x) else x)

        df_test[column] = pd.to_numeric(df_test[column], errors='coerce')







df_test.isnull().sum()

df_test.head()

df_test.isnull().sum()


with open('encoder.pkl', 'rb') as f:
    encoder = pickle.load(f)

new_data = df_test[['weight','processor_name','processor_brand','brand','ram_type']]

encoded_new_data_df = pd.DataFrame()

for _, row in new_data.iterrows():
    try:
        encoded_row = encoder.transform([row])
        encoded_row_df = pd.DataFrame(encoded_row.toarray(), columns=encoder.get_feature_names_out(['weight','processor_name','processor_brand','brand','ram_type']))
        encoded_new_data_df = pd.concat([encoded_new_data_df, encoded_row_df], ignore_index=True)
    except ValueError:
        pass



encoded_new_data_df.reset_index(drop=True, inplace=True)
df_test.reset_index(drop=True, inplace=True)


df_test_encoded = pd.concat([df_test, encoded_new_data_df], axis=1)

columns_to_drop = ['weight', 'processor_name', 'processor_brand', 'brand', 'ram_type']
df_test_encoded.drop(columns_to_drop, axis=1, inplace=True)

df_test = df_test_encoded

df_test.isnull().sum()

df_test.shape



numerical_preprocessing = {}
numerical_columns = df_test.select_dtypes(include=[ 'int64']).columns


with open('numerical_preprocessing.pkl', 'rb') as f:
    numerical_preprocessing=pickle.load(f)

numerical_preprocessing.items()

for column in numerical_columns:
    q1 = df_test[column].quantile(0.25)
    q3 = df_test[column].quantile(0.75)
    IQR = q3 - q1

    lower_bound = q1 - 1.5*IQR
    upper_bound = q3 + 1.5*IQR

    outliers = df_test[(df_test[column] < lower_bound) | (df_test[column] > upper_bound)]
    print('Number of outliers in "' + column + '" : ' + str(len(outliers)))

for column, bounds_info in numerical_preprocessing.items():
    lower_bound = bounds_info['lower_bound']
    upper_bound = bounds_info['upper_bound']
    df_test[column] = df_test[column].clip(lower=lower_bound, upper=upper_bound)


for column in numerical_columns:
    q1 = df_test[column].quantile(0.25)
    q3 = df_test[column].quantile(0.75)
    IQR = q3 - q1

    lower_bound = q1 - 1.5*IQR
    upper_bound = q3 + 1.5*IQR

    outliers = df_test[(df_test[column] < lower_bound) | (df_test[column] > upper_bound)]
    print('Number of outliers in "' + column + '" : ' + str(len(outliers)))

with open('scaler.pkl', 'rb') as f:
    scaler=pickle.load(f)

df_test.head()

import pickle
from sklearn.preprocessing import RobustScaler
with open('scaler.pkl', 'rb') as f:
    scaler = pickle.load(f)

df_test_without_rating = df_test.drop(columns=['rating'])

robust_scaled_data = scaler.transform(df_test_without_rating)

df_test_scaled = pd.DataFrame(robust_scaled_data, columns=df_test_without_rating.columns)

df_test_scaled['rating'] = df_test['rating']


print( df_test_scaled)

with open('top_features.pkl', 'rb') as f:
    s_features=pickle.load(f)

df_test_scaled.columns

y=df_test_scaled['rating']

print(y)

df_test_scaled = df_test_scaled.drop(columns=s_features, axis=1)

df_test_scaled.columns

X=df_test_scaled

with open('gb_model.pkl', 'rb') as f:
    gb=pickle.load(f)

X.columns

y

from sklearn.metrics import accuracy_score

y_pred=gb.predict(X)


test_accuracy = accuracy_score(y, y_pred) * 100
print("gb:", test_accuracy, '%')

with open('lr_model.pkl', 'rb') as f:
    lr=pickle.load(f)

y_pred=lr.predict(X)


test_accuracy = accuracy_score(y, y_pred) * 100
print("lr:", test_accuracy, '%')

with open('rf_model.pkl', 'rb') as f:
    rf=pickle.load(f)

y_pred=rf.predict(X)


test_accuracy = accuracy_score(y, y_pred) * 100
print("rf:", test_accuracy, '%')

with open('voting_clf_model.pkl', 'rb') as f:
    voting=pickle.load(f)

y_pred=voting.predict(X)


test_accuracy = accuracy_score(y, y_pred) * 100
print("voting:", test_accuracy, '%')

with open('stacking_model.pkl', 'rb') as f:
    stacking=pickle.load(f)

y_pred=stacking.predict(X)


test_accuracy = accuracy_score(y, y_pred) * 100
print("stacking:", test_accuracy, '%')