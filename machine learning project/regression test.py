# -*- coding: utf-8 -*-
"""Test script CS - lasttt

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hlSB8yNNBoa5YEqAX6wBt5T6jLHj4Bc9
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import sklearn as sk
from sklearn.linear_model import Ridge , Lasso
from sklearn.ensemble import RandomForestRegressor , GradientBoostingRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from sklearn.preprocessing import RobustScaler
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.pipeline import make_pipeline
from sklearn.tree import DecisionTreeRegressor
from sklearn.feature_selection import mutual_info_classif
from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestRegressor
import pickle
import re

df_test=pd.read_csv(r"/content/ElecRegTest.csv")

# df_train, df_test = train_test_split(data, test_size=0.2, random_state=20)

df_test.shape

df_test.value_counts()

# Load the preprocessing steps from the pickled file
with open('preprocessing_steps.pkl', 'rb') as f:
    preprocessing_steps = pickle.load(f)

# Apply the same replacements for each column using the loaded preprocessing steps
for column, replacements in preprocessing_steps.items():
    if column in df_test.columns:
        try:
            df_test[column] = df_test[column].replace(replacements)
        except Exception as e:
            print(f"Error occurred while replacing values in column '{column}': {e}")

df_test['ram_type'].value_counts()

with open('modes.pkl', 'rb') as f:
    modes_loaded = pickle.load(f)

# Replace null values with the loaded modes
for column in df_test.columns:
    mode_value = modes_loaded.get(column)  # Get the mode for the column
    if mode_value is not None:  # Check if mode exists
        df_test[column].fillna(mode_value, inplace=True)  # Replace nulls with mode

columns_to_process = ['ram_gb', 'ssd', 'hdd', 'os', 'graphic_card_gb', 'rating', 'warranty']
for column in columns_to_process:
    if column in df_test.columns:
        df_test[column] = df_test[column].astype(str).str.split().str[0]
        df_test[column] = pd.to_numeric(df_test[column], errors='coerce')
        df_test[column] = df_test[column].fillna(0).astype(np.int64)

target=df_test['rating']

df_test=df_test.drop(columns=['rating'])

parts = df_test['processor_gnrtn'].str.split(r'[a-zA-Z]', expand=True)
parts = parts.apply(lambda x: x.str.strip()).stack().reset_index(drop=True)
df_test['processor_gnrtn'] = parts

df_test.isnull().sum()

# Replace null values with the loaded modes
for column in df_test.columns:
    mode_value = modes_loaded.get(column)  # Get the mode for the column
    if mode_value is not None:  # Check if mode exists
        df_test[column].fillna(mode_value, inplace=True)  # Replace nulls with mode

df_test['processor_gnrtn'].value_counts()

df_test.columns

df_test['ram_ssd_interaction'] = df_test['ram_gb'] * df_test['ssd']
df_test=df_test.drop(columns=['ram_gb','ssd'])
df_test['numberofrating_price_interaction'] = df_test['Number of Ratings'] * df_test['Price']
df_test=df_test.drop(columns=['Price'])
df_test['rating_reviews_interaction'] = df_test['Number of Ratings'] * df_test['Number of Reviews']
df_test=df_test.drop(columns=['Number of Ratings','Number of Reviews'])
df_test['hdd_os_interaction'] = df_test['hdd'] * df_test['os']
df_test=df_test.drop(columns=['os','hdd'])

features_encoded = pd.get_dummies(df_test[['weight','processor_name','processor_brand','brand','ram_type']])
df_test = df_test.drop(['weight', 'processor_name', 'processor_brand', 'brand', 'ram_type'], axis=1)
df_test = pd.concat([df_test, features_encoded], axis=1)

df_test.columns

numerical_preprocessing = {}
numerical_columns = df_test.select_dtypes(include=[ 'int64']).columns


# Save the preprocessed numerical columns using pickle
with open('numerical_preprocessing.pkl', 'rb') as f:
    numerical_preprocessing=pickle.load(f)

import pandas as pd

# Assume df_test is your DataFrame and numerical_preprocessing contains the bounds information

# Iterate over numerical columns and handle outliers
for column, bounds_info in numerical_preprocessing.items():
    lower_bound = bounds_info['lower_bound']
    upper_bound = bounds_info['upper_bound']

    # Convert column to numeric type, ignoring errors
    df_test[column] = pd.to_numeric(df_test[column], errors='coerce')

    # Clip values within bounds after converting to numeric
    df_test[column] = df_test[column].clip(lower=lower_bound, upper=upper_bound)

df_test.columns

df_test.info()

# Load top_features from the pickle file

with open('top_features_mut.pkl', 'rb') as f:
    top_features = pickle.load(f)

with open('columns_to_drop_corr.pkl', 'rb') as f:
    s_features=pickle.load(f)

df_test = df_test.drop(columns=s_features, axis=1)

# Select numeric columns
numeric_columns = df_test.select_dtypes(include=[np.number]).columns

# Select non-numeric columns
non_numeric_columns = df_test.select_dtypes(exclude=[np.number]).columns

# Initialize a list to store selected features
selected_features = []

# Check if each feature in top_features exists in df_test columns
for feature in top_features:
    if feature in df_test.columns:
        # Add the feature to the list of selected features
        selected_features.append(feature)
    else:
        # If the feature doesn't exist in df_test.columns, add a new column with zeros for the feature
        df_test[feature] = 0
        # Add the feature to the list of selected features
        selected_features.append(feature)

# Use selected_features list to subset df_test
df_test = df_test[list(numeric_columns) + selected_features]

df_test.columns

top_features

df_test.columns



top_features

df_test.columns

# boolean
for column in df_test.columns:
    if df_test[column].dtype == bool:
        df_test[column] = df_test[column].astype(int)

y=target
X=df_test

X.columns

with open('random_forest_model.pkl', 'rb') as f:
    rf=pickle.load(f)

y_pred=rf.predict(X)

mse = mean_squared_error(y, y_pred)

r2 = r2_score(y, y_pred)

print(f"Test MSE: {mse:.4f}")
print(f"R2: {r2:.8f}")

