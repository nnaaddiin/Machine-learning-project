# -*- coding: utf-8 -*-
"""milestone1 pattern

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11b6z2QehFFYAo1356JI5Mx3xj_SCWL7d
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import sklearn as sk
from sklearn.linear_model import Ridge , Lasso
from sklearn.ensemble import RandomForestRegressor , GradientBoostingRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from sklearn.preprocessing import RobustScaler
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.pipeline import make_pipeline
from sklearn.tree import DecisionTreeRegressor
from sklearn.feature_selection import mutual_info_classif
from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestRegressor

data=pd.read_csv("/content/ElecDeviceRatingPrediction.csv")
data['Touchscreen'] = data['Touchscreen'].replace({'Yes': 1, 'No': 0})
data['msoffice'] = data['msoffice'].replace({'Yes': 1, 'No': 0})
data['warranty'] = data['warranty'].replace('No warranty', 0)
data['processor_gnrtn'] = data['processor_gnrtn'].replace('Not Available', 0)
data.head()
print(data.isnull().sum())
#sb.pairplot(data)
sns.distplot(data['Price'])
features=data
for column in features.columns:
 features[column].fillna(features[column].mode(), inplace=True)
 sns.boxplot(data=features,palette='rainbow',orient='h')
 features.describe()
 features.info()
sns.set(style="whitegrid")
plt.figure(figsize=(8, 6))
sns.histplot(data['rating'], bins=20, kde=True, color='skyblue')
plt.title('Distribution of Ratings')
plt.xlabel('Rating')
plt.ylabel('Frequency')
plt.show()

categorical_columns = ['weight', 'processor_name', 'processor_brand', 'brand', 'ram_type', 'warranty', 'Touchscreen', 'msoffice']
for column in categorical_columns:
    plt.figure(figsize=(10, 6))
    sns.countplot(x=column, data=data, hue='rating', palette='Set2')
    plt.title(f'Counts of {column} with respect to Rating')
    plt.xlabel(column)
    plt.ylabel('Count')
    plt.xticks(rotation=45)
    plt.legend(title='Rating')
    plt.show()

columns_to_process = ['ram_gb', 'ssd', 'hdd', 'os', 'graphic_card_gb', 'rating', 'warranty']
for column in columns_to_process:
    if column in features.columns:
        features[column] = features[column].astype(str).str.split().str[0]
        features[column] = pd.to_numeric(features[column], errors='coerce')
        features[column] = features[column].fillna(0).astype(np.int64)
target=features['rating']
features=features.drop(columns=['rating'])
print(target)
parts = features['processor_gnrtn'].str.split(r'[a-zA-Z]', expand=True)
parts = parts.apply(lambda x: x.str.strip()).stack().reset_index(drop=True)
features['processor_gnrtn'] = parts
print(parts)
print(features)
features['ram_ssd_interaction'] = features['ram_gb'] * features['ssd']
features=features.drop(columns=['ram_gb','ssd'])
features['numberofrating_price_interaction'] = features['Number of Ratings'] * features['Price']
features=features.drop(columns=['Price'])
features['rating_reviews_interaction'] = features['Number of Ratings'] * features['Number of Reviews']
features=features.drop(columns=['Number of Ratings','Number of Reviews'])
features['hdd_os_interaction'] = features['hdd'] * features['os']
features=features.drop(columns=['os','hdd'])

features_encoded = pd.get_dummies(features[['weight','processor_name','processor_brand','brand','ram_type']])
features = features.drop(['weight', 'processor_name', 'processor_brand', 'brand', 'ram_type'], axis=1)
features = pd.concat([features, features_encoded], axis=1)
columns_to_factorize = ['processor_gnrtn']
for column in columns_to_factorize:
    features[column] = pd.factorize(features[column])[0]
numerical_columns = features.select_dtypes(include=[ 'int64']).columns
for column in numerical_columns:
    features[column] = features[column].fillna(features[column].median())
    Q1 = features[column].quantile(0.25)
    Q3 = features[column].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    features[column] = features[column].clip(lower=lower_bound, upper=upper_bound)
sns.boxplot(data=features[numerical_columns], palette='rainbow', orient='h')
plt.title('Box plot of features without outliers')
plt.show()

print(features)

scaler = RobustScaler()
robust_scaled_data = scaler.fit_transform(features)
numeric_columns = features.select_dtypes(include=['float64', 'int64']).columns
numeric_columns = features.select_dtypes(include=['int64', 'float64']).columns
selected_columns = features[numeric_columns]
selected_columns['rating'] = target
correlation_matrix = selected_columns.corr()
plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Correlation Matrix with Ratings')
plt.show()
strong_correlations = correlation_matrix.index[(correlation_matrix['rating'].abs() >= 0.04) & (correlation_matrix['rating'].abs() < 1)]
numeric_columns = features.select_dtypes(include=['float64', 'int64']).columns
features_numeric = features[numeric_columns]
features_numeric_filtered = features_numeric[strong_correlations]
columns_to_drop = [col for col in features_numeric if col not in features_numeric_filtered]
features = features.drop(columns=columns_to_drop, axis=1)
print(features)

from sklearn.feature_selection import mutual_info_classif
import pandas as pd
numeric_columns = features.select_dtypes(include=[np.number]).columns
non_numeric_columns = features.select_dtypes(exclude=[np.number]).columns
mutual_info_scores = mutual_info_classif(features[non_numeric_columns], target)
feature_scores = pd.DataFrame({
    'Feature': non_numeric_columns,
    'Mutual_Information': mutual_info_scores
})
feature_scores_sorted = feature_scores.sort_values(by='Mutual_Information', ascending=False)
top_features = feature_scores_sorted.head(26)['Feature'].values
features = features[list(numeric_columns) + list(top_features)]
print(features.head())

for column in features.columns:
    if features[column].dtype == bool:
        features[column] = features[column].astype(int)
print(features)

print(features)

X=features
y=target
models = {
    "Ridge": Ridge(alpha=20),
    "Decision Tree": DecisionTreeRegressor(),
    "Random Forest": RandomForestRegressor(n_estimators=100, random_state=42),
    "Gradient Boosting": GradientBoostingRegressor(n_estimators=50, learning_rate=0.1, random_state=42)
}
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
results = {}
param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [None, 5, 10],
    'min_samples_split': [2, 5, 10]
}
rf_model = RandomForestRegressor(random_state=42)
grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')
grid_search.fit(X_train, y_train)
best_params = grid_search.best_params_
best_model = grid_search.best_estimator_
models["grid_search"] = best_model
mse = mean_squared_error(y_test, best_model.predict(X_test))
r2 = r2_score(y_test, best_model.predict(X_test))
print("Best Random Forest Hyperparameters:", best_params)
print("Best Random Forest Test MSE:", mse)
print("Best Random Forest Test R2:", r2)
results = {}
results["grid_search"] = {'MSE': mse, 'R2': r2}
for name, model in models.items():
    model.fit(X_train, y_train)
    predictions = model.predict(X_test)
    mse = mean_squared_error(y_test, predictions)
    r2 = r2_score(y_test, predictions)
    results[name] = {'MSE': mse, 'R2': r2}
    cv_scores = cross_val_score(model, X, y, cv=5, scoring='neg_mean_squared_error')
    mean_cv_score = -np.mean(cv_scores)
    print(f"{name}:")
    print(f"Test MSE: {mse:.4f}")
    print(f"R2: {r2:.8f}")
    print(f"Cross-Validation MSE: {mean_cv_score:.8f}\n")

threshold = 0.1
for name, result in results.items():
    accuracy = sum(abs(predictions - y_test) <= threshold) / len(y_test) * 100
    print(f"{name}:")
    print(f"  Accuracy: {accuracy:.2f}%")

# Visualize the results of the models
for name, result in results.items():
    plt.figure(figsize=(10, 6))
    plt.bar(['Test MSE', 'Cross-Validation MSE'], [result['MSE'], mean_cv_score], color=['blue', 'green'])
    plt.title(f'Mean Squared Error for {name}')
    plt.xlabel('Metrics')
    plt.ylabel('Mean Squared Error')
    plt.show()